{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step: Load data and packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext lab_black"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pyodbc\n",
        "import numpy as np\n",
        "from skimpy import clean_columns\n",
        "from pyprojroot import here\n",
        "import os\n",
        "import PyPDF2\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import docx\n",
        "import nltk\n",
        "from PyPDF2 import PdfReader\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from analysis.fun_text_analyzer import text_analyzer\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "path_data = here(\"./data\")\n",
        "os.chdir(path_data)\n",
        "\n",
        "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682703545269
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step: Combine text by case id, and lower text"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = text_analyzer()\n",
        "cv_text = analyzer.read_word_file(\"./CV_Matt_Hanauer.docx\")\n",
        "job_description_text = analyzer.read_word_file(\"./job_example.docx\")\n",
        "\n",
        "\n",
        "cv_text_tokens = analyzer.preprocess_text(cv_text)\n",
        "job_description_text_tokens = analyzer.preprocess_text(job_description_text)\n",
        "similarity_score = analyzer.compare_texts(cv_text_tokens, job_description_text_tokens)\n",
        "cv_word_freq = analyzer.calculate_word_frequency(cv_text_tokens)\n",
        "job_description_word_freq = analyzer.calculate_word_frequency(\n",
        "    job_description_text_tokens\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cosine_similarity' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m cv_text_tokens \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpreprocess_text(cv_text)\n\u001b[1;32m      7\u001b[0m job_description_text_tokens \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mpreprocess_text(job_description_text)\n\u001b[0;32m----> 8\u001b[0m similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv_text_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_description_text_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m cv_word_freq \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mcalculate_word_frequency(cv_text_tokens)\n\u001b[1;32m     10\u001b[0m job_description_word_freq \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mcalculate_word_frequency(\n\u001b[1;32m     11\u001b[0m     job_description_text_tokens\n\u001b[1;32m     12\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/analysis/fun_text_analyzer.py:123\u001b[0m, in \u001b[0;36mtext_analyzer.compare_texts\u001b[0;34m(self, text1_tokens, text2_tokens, top_n_scores)\u001b[0m\n\u001b[1;32m    121\u001b[0m text1_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(text1_sentences, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m text2_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode(text2_sentences, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 123\u001b[0m similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m(text1_embedding, text2_embedding)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_score\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cosine_similarity' is not defined"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682703550846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_score"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682703531343
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_description_word_freq"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "FreqDist({'data': 16, 'experience': 8, 'technical': 7, 'science': 6, 'business': 6, 'team': 4, 'availity': 4, 'years': 4, 'cloud': 4, 'production': 4, ...})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682702958283
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 10 words from the job description\n",
        "top_n = 10\n",
        "top_job_description_words = [\n",
        "    word for word, freq in job_description_word_freq.most_common(top_n)\n",
        "]\n",
        "\n",
        "# Find the missing top 10 words in the resume\n",
        "missing_keywords = []\n",
        "for word in top_job_description_words:\n",
        "    if word not in cv_word_freq:\n",
        "        missing_keywords.append(word)\n",
        "\n",
        "missing_keywords"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "['technical', 'availity', 'years', 'cloud', 'production']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682700769353
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "98def2bbe4c17ca6f7446c23f6cb6fc94941e782507d089d8d0095a990429397"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}